{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/azhuavlev/PycharmProjects/ml-neuman_mano\")\n",
    "\n",
    "import lighning_models\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import nerf\n",
    "import dataset_canonical_space\n",
    "from torch.utils.data import DataLoader\n",
    "import dataset_from_files\n",
    "import glob\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pytorch3d\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "from IPython import display\n",
    "from PIL import Image\n",
    "from pytorch3d.renderer import (\n",
    "    FoVPerspectiveCameras,\n",
    "    NDCMultinomialRaysampler,\n",
    "    MonteCarloRaysampler,\n",
    "    EmissionAbsorptionRaymarcher,\n",
    "    ImplicitRenderer,\n",
    "    RayBundle,\n",
    "    ray_bundle_to_ray_points,\n",
    ")\n",
    "# Data structures and functions for rendering\n",
    "from pytorch3d.structures import Volumes\n",
    "from pytorch3d.transforms import so3_exp_map\n",
    "from tqdm import tqdm\n",
    "\n",
    "from generate_cow_renders import generate_cow_renders\n",
    "from plot_image_grid import image_grid\n",
    "\n",
    "from helpers import *\n",
    "from nerf import *\n",
    "\n",
    "from data_io import neuman_helper\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-09T11:50:25.299294Z",
     "end_time": "2023-07-09T11:50:34.188802Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-07-09T11:51:30.928626Z",
     "end_time": "2023-07-09T11:51:40.458618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55, 8, 11, 10, 32, 22, 31, 49, 57, 35, 48, 7, 38, 1, 24, 41, 18, 56, 30, 17, 36, 58, 28, 51]\n",
      "WARNING: You are using a MANO model, with only 10 shape coefficients.\n",
      "WARNING: You are using a MANO model, with only 10 shape coefficients.\n",
      "WARNING: You are using a MANO model, with only 10 shape coefficients.\n",
      "WARNING: You are using a MANO model, with only 10 shape coefficients.\n",
      "min_depth tensor(0.9344)\n",
      "max_depth tensor(1.2658)\n",
      "render_size_x 512\n",
      "render_size_y 334\n",
      "WARNING: You are using a MANO model, with only 10 shape coefficients.\n",
      "min_depth tensor(0.9344)\n",
      "max_depth tensor(1.2658)\n",
      "render_size_x 512\n",
      "render_size_y 334\n",
      "tensor([[-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-5.9605e-08, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-1.1921e-07, -0.0000e+00,  3.0000e-01],\n",
      "        [ 1.1921e-07, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [ 1.4901e-08, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-5.9605e-08, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-5.9605e-08, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01],\n",
      "        [-0.0000e+00, -0.0000e+00,  3.0000e-01]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_net/manifoldnet/azhuavlev/conda_envs/neuman_kaolin/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /scratch_net/manifoldnet/azhuavlev/conda_envs/neuman ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 334, 96, 1]) torch.Size([1, 512, 334, 96, 3])\n",
      "torch.Size([1, 512, 334, 96, 1]) torch.Size([1, 512, 334, 96, 3])\n"
     ]
    }
   ],
   "source": [
    "# disable pytorch gradient computation\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "data_path = '/home/azhuavlev/Desktop/Data/InterHand_Neuman/03'\n",
    "all_ids = list(range(len(glob.glob(os.path.join(data_path, 'cameras', '*.json')))))\n",
    "\n",
    "# use 80% of the data for training, randomize the order\n",
    "np.random.shuffle(all_ids)\n",
    "train_ids = all_ids[:int(0.6 * len(all_ids))]\n",
    "test_ids = all_ids[int(0.6 * len(all_ids)):]\n",
    "print(test_ids)\n",
    "\n",
    "train_dataset = dataset_from_files.NeumanDataset(data_path, train_ids)\n",
    "test_dataset = dataset_from_files.NeumanDataset(data_path, test_ids)\n",
    "full_dataset = dataset_from_files.NeumanDataset(data_path, all_ids)\n",
    "\n",
    "# We sample 6 random cameras in a minibatch.\n",
    "batch_size = 1\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=5)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "full_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "nerf = nerf.NeuralRadianceField()\n",
    "\n",
    "ckpt_path = '/home/azhuavlev/Desktop/Results/neuman_custom/lightning_logs/version_128/checkpoints/epoch=649-step=23400.ckpt'\n",
    "model = lighning_models.HandModel(dataset=full_loader, nerf_model=nerf).load_from_checkpoint(ckpt_path,\n",
    "                                                                                             dataset=full_loader,\n",
    "                                                                                             nerf_model=nerf)\n",
    "\n",
    "can_dataset = dataset_canonical_space.CanSpaceDataset(n_cameras=20)\n",
    "can_dataloader = DataLoader(can_dataset, batch_size=1, shuffle=False, num_workers=5)\n",
    "\n",
    "trainer = L.Trainer()\n",
    "\n",
    "camera_params, images, silhouettes, manos = can_dataset[0:1]\n",
    "\n",
    "batch_cameras = FoVPerspectiveCameras(\n",
    "    R=camera_params['R'],\n",
    "    T=camera_params['t'],\n",
    "    znear=camera_params['znear'],\n",
    "    zfar=camera_params['zfar'],\n",
    "    device=torch.device(\"cuda\"),\n",
    ")\n",
    "model = model.to('cuda')\n",
    "\n",
    "ray_densities, ray_colors = model.get_nerf_output(\n",
    "    camera=batch_cameras,\n",
    ")\n",
    "print(ray_densities.shape, ray_colors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction occupied 0.0018837447175960578\n"
     ]
    }
   ],
   "source": [
    "print('fraction occupied', np.mean(ray_densities.cpu().numpy() > 0.1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-09T11:52:05.157247Z",
     "end_time": "2023-07-09T11:52:05.241863Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
