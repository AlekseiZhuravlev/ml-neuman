{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-08-08T13:05:52.394383Z",
     "end_time": "2023-08-08T13:05:58.270264Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/azhuavlev/PycharmProjects/ml-neuman_mano/pytorch3d_nerf\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pytorch3d\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "from IPython import display\n",
    "from PIL import Image\n",
    "from pytorch3d.renderer import (\n",
    "    FoVPerspectiveCameras,\n",
    "    NDCMultinomialRaysampler,\n",
    "    MonteCarloRaysampler,\n",
    "    EmissionAbsorptionRaymarcher,\n",
    "    ImplicitRenderer,\n",
    "    RayBundle,\n",
    "    ray_bundle_to_ray_points,\n",
    "PerspectiveCameras,\n",
    ")\n",
    "# Data structures and functions for rendering\n",
    "from pytorch3d.structures import Volumes\n",
    "from pytorch3d.transforms import so3_exp_map\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import dataset_extr_to_mano, dataset_canonical_space\n",
    "import lighning_models\n",
    "\n",
    "from nerf_models import nerf_big_no_warp\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# disable pytorch gradient computation\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "data_path = '/home/azhuavlev/Desktop/Data/InterHand_Neuman/03'\n",
    "all_ids = list(range(len(glob.glob(os.path.join(data_path, 'cameras', '*.json')))))\n",
    "\n",
    "# use 80% of the data for training, randomize the order\n",
    "np.random.shuffle(all_ids)\n",
    "train_ids = all_ids[:int(0.6 * len(all_ids))]\n",
    "test_ids = all_ids[int(0.6 * len(all_ids)):]\n",
    "print(test_ids)\n",
    "\n",
    "train_dataset = dataset_extr_to_mano.NeumanDataset(data_path, train_ids)\n",
    "test_dataset = dataset_extr_to_mano.NeumanDataset(data_path, test_ids)\n",
    "full_dataset = dataset_extr_to_mano.NeumanDataset(data_path, all_ids)\n",
    "\n",
    "# We sample 6 random cameras in a minibatch.\n",
    "batch_size = 1\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=5)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "full_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-08T13:05:58.274717Z",
     "end_time": "2023-08-08T13:06:04.334413Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "field = nerf_big_no_warp.NeuralRadianceField()\n",
    "\n",
    "# ckpt_path = '/itet-stor/azhuavlev/net_scratch/Projects/Results/neuman_custom/lightning_logs/big_sil_loss_1000_mask_0.05_dilation_10_sampling_4096_64_depth_105_huber_mask_huber/checkpoints/epoch=1999-step=42000.ckpt'\n",
    "# ckpt_path = '/itet-stor/azhuavlev/net_scratch/Projects/Results/neuman_custom/lightning_logs/big_clipped_sil_loss_99999_lr_99999_mask_1_dilation_10_sampling_8192_32_depth_105_huber_mask_huber/checkpoints/epoch=9999-step=210000.ckpt'\n",
    "# ckpt_path = '/home/azhuavlev/Desktop/Results/neuman_custom/lightning_logs/small_warp_clipped_sil_loss_99999_lr_99999_mask_0.3_dilation_10_sampling_8192_32_depth_105_huber/checkpoints/epoch=2399-step=86400.ckpt'\n",
    "ckpt_path = '/home/azhuavlev/Desktop/Results/neuman_custom/lightning_logs/big_allLosses/checkpoints/epoch=4999-step=105000.ckpt'\n",
    "\n",
    "model = lighning_models.HandModel(nerf_model=field).load_from_checkpoint(ckpt_path,\n",
    "                                                                                             dataset=full_loader,\n",
    "                                                                                             nerf_model=field)\n",
    "model = model.to('cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-08T13:06:04.334962Z",
     "end_time": "2023-08-08T13:06:04.461577Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warp_points\n",
    "import trimesh\n",
    "\n",
    "show_ids = [2]\n",
    "show_dataset = dataset_extr_to_mano.NeumanDataset(data_path, show_ids)\n",
    "show_loader = DataLoader(show_dataset, batch_size=1, shuffle=True, num_workers=5)\n",
    "\n",
    "point_cloud_list = []\n",
    "for batch in show_loader:\n",
    "\n",
    "    camera_params, images, silhouettes, _, manos = batch\n",
    "\n",
    "    batch_cameras = PerspectiveCameras(\n",
    "        R=camera_params['R_pytorch3d'],\n",
    "        T=camera_params['t_pytorch3d'],\n",
    "        focal_length=camera_params['focal'],\n",
    "        principal_point=camera_params['princpt'],\n",
    "        in_ndc=False,\n",
    "        image_size=camera_params['image_size'],\n",
    "        device='cpu'\n",
    "    )\n",
    "    raysampler_train = NDCMultinomialRaysampler(\n",
    "                image_height=int(camera_params['image_size'][0][1]),\n",
    "                image_width=int(camera_params['image_size'][0][0]),\n",
    "                n_pts_per_ray=256,\n",
    "                min_depth=0.1,\n",
    "                max_depth=1,\n",
    "                stratified_sampling=False,\n",
    "            )\n",
    "    with torch.no_grad():\n",
    "\n",
    "        depths = batch_cameras.get_world_to_view_transform().transform_points(\n",
    "            manos['verts']\n",
    "        )[:, :, 2:]\n",
    "\n",
    "        ray_bundle = raysampler_train(\n",
    "            cameras=batch_cameras,\n",
    "            min_depth=depths.min() * 0.95,\n",
    "            max_depth=depths.max() * 1.05,\n",
    "        )\n",
    "        rays_points_world = ray_bundle_to_ray_points(ray_bundle)\n",
    "\n",
    "        print('rays_points_world', rays_points_world.device)\n",
    "\n",
    "        # Warp the rays to the canonical view.\n",
    "        ray_points_can, ray_directions_can = warp_points.warp_points_batched_with_cpu(\n",
    "            rays_points_world,\n",
    "            manos['verts'],\n",
    "            manos['Ts'],\n",
    "        )\n",
    "\n",
    "        print('ray_points_can', ray_points_can.device)\n",
    "        # get output of nerf model\n",
    "        rays_densities, rays_colors = model.neural_radiance_field.batched_forward_with_cpu(\n",
    "            ray_points=ray_points_can, ray_directions=ray_directions_can, n_batches=36\n",
    "        )\n",
    "\n",
    "    print('fraction occupied > 0.1', np.mean(rays_densities.cpu().numpy() > 0.1))\n",
    "    print('fraction occupied > 0.9', np.mean(rays_densities.cpu().numpy() > 0.9))\n",
    "\n",
    "\n",
    "\n",
    "    # keep the points with opacity > 0.1\n",
    "    points_reshaped = rays_points_world.reshape(-1, 3)\n",
    "    rays_colors_reshaped = rays_colors.reshape(-1, 3)\n",
    "    rays_densities_reshaped = rays_densities.reshape(-1, 1)\n",
    "\n",
    "    threshold = 0.01\n",
    "\n",
    "    points_reshaped = points_reshaped[rays_densities.reshape(-1) > threshold].cpu().numpy()\n",
    "    rays_colors_reshaped = rays_colors_reshaped[rays_densities.reshape(-1) > threshold].cpu().numpy()\n",
    "    rays_densities_reshaped = rays_densities_reshaped[rays_densities.reshape(-1) > threshold].cpu().numpy()\n",
    "\n",
    "    # print('rays_densities_reshaped.shape', rays_densities_reshaped.shape, rays_densities_reshaped.dtype, rays_densities_reshaped.min(), rays_densities_reshaped.max())\n",
    "    # print('rays_colors_reshaped.shape', rays_colors_reshaped.shape, rays_colors_reshaped.dtype, rays_colors_reshaped.min(), rays_colors_reshaped.max())\n",
    "    rays_colors_rgba = np.concatenate((rays_colors_reshaped, rays_densities_reshaped), axis=1)\n",
    "\n",
    "    # convert colors from [0, 1] to [0, 255]\n",
    "    rays_colors_rgba = rays_colors_rgba * 255\n",
    "    rays_colors_rgba = rays_colors_rgba.astype(np.uint8)\n",
    "\n",
    "    point_cloud = trimesh.PointCloud(points_reshaped, colors=rays_colors_rgba)\n",
    "    point_cloud_list.append(point_cloud)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.imshow(images[0].cpu().numpy())\n",
    "\n",
    "scene = trimesh.Scene()\n",
    "for point_cloud in point_cloud_list:\n",
    "    scene.add_geometry(point_cloud)\n",
    "\n",
    "mano_mesh = manos['verts'][0].cpu().numpy()\n",
    "# shift mano mesh by 0.2 in z direction\n",
    "mano_mesh[:, 2] += 0.2\n",
    "\n",
    "faces = model.hand_model.faces\n",
    "mano_mesh = trimesh.Trimesh(vertices=mano_mesh, faces=faces)\n",
    "\n",
    "# disable light on scene\n",
    "scene.visual = {'ambient': (1.0, 1.0, 1.0)}\n",
    "\n",
    "# scene.add_geometry(mano_mesh)\n",
    "# scene.add_geometry(trimesh.creation.axis(axis_length=0.15, axis_radius = 0.001, origin_size=0.001))\n",
    "\n",
    "scene.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-08T13:09:57.843186Z",
     "end_time": "2023-08-08T13:10:21.945463Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-08T13:06:28.652811Z",
     "end_time": "2023-08-08T13:06:28.652923Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
